Ok, this has nothing to do with JavaScript, but its easier for me to just bunch my notes here in with the Javascript notes.

Doing a quick Course on Splunk

So what is Splunk?

Think of data, all data produced by humans and machines, from Structured Data, Unstructured data, and Machine code, etc. Splunk takes that data and makes it useful by producing reports, alerts, and dashboards.

Its like modern organization.

So Plunk takes all this data (like how a machine logs everything), logs it, cleans it, formats it, and makes it sing.

Splunk is especially great at reading machine data. Its biggest superpower is parsing Machine data. (Data generated by machines (log data thats usally encrypted and not human readable))

Splunk can look for patterns in that unreadable data, and label that data with feilds/names.

We can take those feilds and build intellegence systems that show us the data so we can understand it.

Another way to put it, Splunk turns Unstructured data into insights.

some rules with Splunk

1. The best place to get help with Splunk is the Splunk Community Answers
2. Splunk IS NOT a bussiness intelligence tool. It is an IT operations tool that consumes machine-data in real time. Most Bussiness intelligence tools do not consume and analyze data in real time.
3. Splunk can be used to investigate, alert, build dashboards, and build reports.

Now - Deploying Spunk

but first a note on configuraton files

1. everything Splunk does is governed by configuration files.
2. Configuration files are stored in the /etc, and they have the .conf extension
3. Confugration files are layered. You can have .conf files that have the same name in different directories.
4. NEVER EDIT .conf FILES IN THE DEFAULT DIRECTORY
5. The /etc/<app>/default directory contains preconfigured versions of .conf files.
6. Instead use the Local Directory
7. The /etc/<app>/local directory is where the custom configurations are stored.

Now the Configuration File Structure
.conf files are build on Stanza's and then underneath it attribute values

[Stanza]
Attribute = Value

Splunk offers 2 main deployment models.
Cloud & On Premises

regarldess which deployment you use the data pipeline is the same
IPIS
input - forwarded data, uploaded data, network data, scripts (Splunk is consuming data, but doens't look at it)
parsing - examines the data, addes metadata (Splunk looks at the data)
indexing - data divided into events. Wrties the data to the disk in "buckets" (stores its work in directories, it calls buckets)
searching - user interaction with the data. (self explanetory)

To scale your system, you can spread the functionality accross multiple specialized instances of splunk. No matter how large you scale, you installing only one of two types of splunk instances, a universal fowarder, or a splunk enterprise instalation

This all makes up every splunk deployments

Forwarder =>
(then below the Deployer)
Heavy Forwarder => Search Head => Deployment Server
Master Cluster Node => License Server => Indexer

The 1st deployment, liek personal deployments -

So when you install Splunk on a Computer, that instalation serves as a Search Head and an Indexer that has up to 10 fowarders and appropriate for up to 10 users

The 2nd deployment is enterpise deployment

You have a single search head, two to three indexers, 100-20 fowarders, and appropriate for 100 - 200 users

A 3rd type of Deployment is a Distributed Search

In this config, you build search head clusters governed by a deployer. It distributed files and configuration updates to all members through a configuration bundle.

A search head cluster is a group of search heads that serve as a central resource for searching. So users can log into any member of the search head cluster and take advantage of clustering a bunch of search heads together. (for performance)

Users can run the same searchs and view the same data for any search head in the cluster

One head is designated as the Search Head Captian and schedals jobs between the clusters

With this deployment there are many indexers and thousands of load-balanced forwarders

The 4th type of deployment is has near infinite scalability. In this config,
called a "Large Enterprise Deployment"

It can have Search Head Clusters, or Indexer Clusters, or Both
And it can have thousands of load-balanced fowarders

- Now how does Splunk Store Data

Splunk adds data to Indexes, the indexes match the places on the disk that Splunk calls buckets.

Splunk comes with several indexes built in, and you can create you own as well
Splunk transforms incoming data into events, and stores it in indexes.
An event is a single row of data that has metadata attached to it.
The default index of Splunk is main and it also has an \_internal index that stores internal logs and a few other indexes that come with splunk.

Again, an event is a single row of data
Data is specified by fields (key values pairs) (like objects in JavaScript)
Splunk adds default fields to all events - Timestamp (time), host (ip address), source (the file from where the source originates), sourcetype (the format of the data)

In Splunk, an index contains compressed raw data from an associated index files, and they are spread out into different directory files depending on their age.

There are 6 default buckets, but only 5 important for us to know about

The 6th bucket is the Fish Bucket and its more advanced

1. Hot Bucket (hotpath) is for newly indexed data for it be Read/Write
2. Warm (warmPath) Contains data rolled from Hot Buckets with no active writing (So Read only) And index has many Warm buckets
3. Cold (coldPath) Takes data from warm buckets and moves it to a different locaton. An index has many cold buckets
4. Frozen (frozenPath) data rolled from cold, where data is deleted or archived
5. Thawed (thawedPath) data resored from an Archive

6. Fish Bucket (this is more advanced so we will not talk about it yet)

With Buckets, you can set up retirerment, archive, back up, configure index sizes, partition index data

Splunk Licensing

You license data ingested per day, not data stored

Daily indexing volume is measured from midnight to midnight by the clock on the license master

Internal Log Data, Duplicate Data, and Meta Data do not count against your licesne.

There are 5 splunk licesne types
Standard / Enterprise/ Sales Trial / Dev Test / Free(barebones with ample restrictions)

There is also a few speciality liscense for Industral Lot and Forwarder

If you exceed your licesne limit within a day, you get a warning
get 5 warnings in a 30 day period, you are offically in violation
If you're in violation, it will annoy you with notices, but it won't be enfroced, so you don't lose functionalty. Splunk allows this to accomidate unexpected bursts of data volume

Regarding Splunk Licensing

1. license pools are created from license stacks
2. Pools are sized for specific purposes
3. Managed by the license master
4. Indexers and other Splink enterprise instances are assigned to a pool

Since fowarders have a unique license, the shouldn't be fowarded to a licesne pool

Largest container is a License Group, within those groups you can create a license stack.
A license stack is a stack of licenses added together
License pools then consume all or most of the license stack, and splunk instances are assigned licesnes out of pools.

Splunk also has Apps and Addons for those apps.

The Apps offer better Visulizaton, Analysis, Reports, Dashboards, and user interfaces

While the Add-ons can give data enrichment, tags, data models and data sets.

A App is simply a collection of .conf files
An Add on is a subset of an app, Add-ons specify do not have Graphical user interfaces cause they are add ons to other apps.

Apps are downloaded from Splunkbase.com - 1st and 3rd party apps, premium and free offerings.

Some of the free apps however will require a license.
